{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096c351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of predicted sale price based some numerical features:\n",
      "15678.414164596194\n",
      "MAE of validation data using train_test_split function: \n",
      "25568.197260273973\n",
      " \n",
      "MAE of validation data using train_test_split function and best max leaf nodes: \n",
      "23972.5862969949\n",
      " \n",
      "MAE for random forest regressor: \n",
      "17220.02464486191\n",
      " \n",
      "MAE for random forest regressor and best max leaf nodes: \n",
      "17208.715832081896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#PLOTTING MAX NODES VS MAE\\nimport matplotlib.pyplot as plt\\n\\nmae_list = []\\nnode_list = list(range(100, 900, 50))  # Less steps to make it faster\\n\\nfor nodes in node_list:\\n    mae = get_mae(nodes, train_X, val_X, train_y, val_y)\\n    mae_list.append(mae)\\n\\nplt.plot(node_list, mae_list)\\nplt.xlabel(\"max_leaf_nodes\")\\nplt.ylabel(\"MAE\")\\nplt.title(\"MAE vs max_leaf_nodes for RandomForest\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "'''\n",
    "Remember answer is in form ID, predicted price!!!   \n",
    "'''\n",
    "\n",
    "#importing the data\n",
    "iowa_file_train = 'train.csv'\n",
    "iowa_train_data = pd.read_csv(iowa_file_train)\n",
    "iowa_file_test = 'test.csv' \n",
    "iowa_test_data = pd.read_csv(iowa_file_test)\n",
    "\n",
    "\n",
    "#This code predicts the sale price of the first 5 properties based on certain features.\n",
    "\n",
    "y = iowa_train_data.SalePrice  #column of SalePrice\n",
    "#print(iowa_data.columns)\n",
    "numerical_features = ['MSSubClass','LotFrontage','LotArea','OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd','MasVnrArea','TotalBsmtSF','1stFlrSF','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','2ndFlrSF','LowQualFinSF','GrLivArea','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','MoSold','YrSold']\n",
    "categorical_features = ['MSZoning','Street','Alley','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC','CentralAir','Electrical','KitchenQual','Functional','FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive','PoolQC','Fence','MiscFeature','SaleType','SaleCondition']\n",
    "X = iowa_train_data[numerical_features + categorical_features]\n",
    "X_encoded = pd.get_dummies(X)\n",
    "# Drop low-importance features\n",
    "dummy_model = RandomForestRegressor(random_state=1)\n",
    "dummy_model.fit(X_encoded, y)\n",
    "importances = pd.Series(dummy_model.feature_importances_, index=X_encoded.columns)\n",
    "low_importance_cols = importances[importances < 0.0005].index\n",
    "X_encoded = X_encoded.drop(columns=low_importance_cols)\n",
    "iowa_model.fit(X_encoded,y)\n",
    "predicted_home_prices = iowa_model.predict(X_encoded)\n",
    "print('MAE of predicted sale price based some numerical features:')\n",
    "#this prediction has a low MAE because DecisionTreeRegressor overfits and fits perfectly to the data\n",
    "\n",
    "\n",
    "#calculating mean absolute error for for data based of features.\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(y,predicted_home_prices))\n",
    "\n",
    "#split training data into training and validation in order to test our model is accurate for new data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X,val_X,train_y,val_y = train_test_split(X_encoded,y,random_state=0)\n",
    "iowa_model = DecisionTreeRegressor()\n",
    "iowa_model.fit(train_X,train_y) \n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "print('MAE of validation data using train_test_split function: ')\n",
    "print(mean_absolute_error(val_y,val_predictions))\n",
    "#this error is very large because decision tree regressor OVERFITS so it is not an accurate model for new unseen data. \n",
    "\n",
    "#define get_mae a function using max_leaf_nodes\n",
    "def get_mae(max_leaf_nodes,train_X,val_X,train_y,val_y):\n",
    "    model = RandomForestRegressor(max_leaf_nodes=max_leaf_nodes,random_state = 1)\n",
    "    model.fit(train_X,train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y,preds_val)\n",
    "    return(mae)\n",
    "\n",
    "\n",
    "#using best max leaf nodes\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X,val_X,train_y,val_y = train_test_split(X_encoded,y,random_state=0)\n",
    "iowa_model = DecisionTreeRegressor(max_leaf_nodes=70,random_state =0)\n",
    "iowa_model.fit(train_X,train_y) \n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "print(' ')\n",
    "print('MAE of validation data using train_test_split function and best max leaf nodes: ')\n",
    "print(mean_absolute_error(val_y,val_predictions))\n",
    "\n",
    "\n",
    "#using random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "iowa_preds = forest_model.predict(val_X)\n",
    "print(' ')\n",
    "print('MAE for random forest regressor: ')\n",
    "print(mean_absolute_error(val_y, iowa_preds))\n",
    "'''\n",
    "#CALCULATING BEST LEAF NODES\n",
    "min = 100000\n",
    "for max_leaf_nodes in range(250,501):\n",
    "    mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    if mae < min:\n",
    "        min = mae\n",
    "        best_leaf_nodes = max_leaf_nodes\n",
    "\n",
    "print('The best max leaf nodes is', best_leaf_nodes)\n",
    "print('The MAE is:', min)\n",
    "\n",
    "'''\n",
    "#using random forest and max_leaf_nodes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_model = RandomForestRegressor(max_leaf_nodes=best_leaf_nodes,random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "iowa_preds = forest_model.predict(val_X)\n",
    "print(' ')\n",
    "print('MAE for random forest regressor and best max leaf nodes: ')\n",
    "print(mean_absolute_error(val_y, iowa_preds))\n",
    "\n",
    "#Actual submission for competition, using our lowest MAE through random forest + 445 max leaf nodes:\n",
    "Id = iowa_test_data.Id  #making a variable which is a list of all Id numbers\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importances = pd.Series(forest_model.feature_importances_, index=X_encoded.columns)\n",
    "feature_importances.nsmallest(10).plot(kind='barh')\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "'''\n",
    "#PLOTTING MAX NODES VS MAE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mae_list = []\n",
    "node_list = list(range(100, 900, 50))  # Less steps to make it faster\n",
    "\n",
    "for nodes in node_list:\n",
    "    mae = get_mae(nodes, train_X, val_X, train_y, val_y)\n",
    "    mae_list.append(mae)\n",
    "\n",
    "plt.plot(node_list, mae_list)\n",
    "plt.xlabel(\"max_leaf_nodes\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.title(\"MAE vs max_leaf_nodes for RandomForest\")\n",
    "plt.show()\n",
    "'''\n",
    "#I removed basement half bath, column because it overfitted the data, mostly zeros, so the MAE was higher with it included. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
